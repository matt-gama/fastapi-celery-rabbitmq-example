# ğŸ“¦ Projeto FastAPI + Celery + RabbitMQ

Este projeto demonstra uma aplicaÃ§Ã£o **FastAPI** que recebe requisiÃ§Ãµes HTTP e executa tarefas assÃ­ncronas usando **Celery** com o broker **RabbitMQ**.

---

## ğŸš€ Estrutura do Projeto

```
fastapi-celery-rabbitmq-example/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ celery_app.py        # InstÃ¢ncia do Celery
â”‚   â””â”€â”€ tasks.py             # Tarefas assÃ­ncronas
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Exemplo PrÃ¡tico

### `app/main.py`
```python

@app.post("/")
async def receive_zapi(payload: RequestPayload):
    """
    Endpoint que recebe a requisiÃ§Ã£o e publica a tarefa para ser processada pelos workers.
    Retorna 200 imediatamente, dizendo que a requisiÃ§Ã£o foi aceita.
    """
    # 1. Aqui vocÃª pode fazer validaÃ§Ãµes rÃ¡pidas, logs, etc.
    data_dict = payload.dict()

    # 2. Chama a task Celery de forma assÃ­ncrona
    print(data_dict)
    process_heavy_operation.delay(data_dict) 
    # .delay() = dispara a tarefa no broker RabbitMQ, sem bloquear

    # 3. Retorna imediatamente
    return {"status": "accepted", "data_received": data_dict}
```

---

### `app/celery_app.py`
```python

import os
from celery import Celery

broker_url = os.getenv("CELERY_BROKER_URL", "amqp://guest:guest@localhost:5672//")
publisher = os.getenv("PUBLISHER", "default")

celery = Celery(
    "my_celery_app",
    broker=broker_url,
    backend=None,
    include=["app.tasks"]  # <--- ADICIONE ESTA LINHA
)

celery.conf.update({
    "task_default_queue": publisher,
    "worker_concurrency": 4,
})
```

---

### `app/tasks.py`
```python
from .celery_app import celery
import time

@celery.task
def process_heavy_operation(data: dict):
    """
    Exemplo de funÃ§Ã£o que serÃ¡ executada em segundo plano pelos workers.
    Pode ser chamada diretamente do MicroserviÃ§o A.
    """
    # Simular trabalho pesado (CPU-bound ou I/O)
    time.sleep(5)  # Exemplo de espera
    # Aqui vocÃª faria integraÃ§Ãµes com IA, supabase, etc.
    print(f"[Worker] Processando data: {data}")
    return {"status": "done", "processed_data": data}

```

---

## ğŸ§ª Como Rodar o Projeto

### 1. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

### `requirements.txt`
```
fastapi
uvicorn
celery
pika
flower
```

---

## ğŸ‡ Subindo o RabbitMQ com Docker (opcional)
```bash
docker run -d --hostname my-rabbit --name some-rabbit \
    -p 5672:5672 -p 15672:15672 \
    -e RABBITMQ_DEFAULT_USER=usuario \
    -e RABBITMQ_DEFAULT_PASS=senha \
    rabbitmq:3-management
```

> Acesse o painel do RabbitMQ: http://localhost:15672

---

## ğŸ”¥ Rodando os serviÃ§os

### Iniciar o servidor FastAPI em modo debug
```bash
uvicorn app.main:app --reload
```

### Iniciar o worker Celery
```bash
celery -A app.celery_app:celery worker --pool=solo --loglevel=info -n worker1@h --concurrency=4
```

### Iniciar o monitor Flower
```bash
celery -A app.celery_app:celery flower --basic_auth=user:password --port=5555
```

> âš ï¸ **IMPORTANTE:** Altere `user:password` para valores seguros em produÃ§Ã£o.

---

## ğŸ“ˆ Escalando a API com Celery

VocÃª pode escalar criando mÃºltiplos workers em paralelo:

```bash
celery -A app.celery_app:celery worker --loglevel=info -n worker2@h --concurrency=4
celery -A app.celery_app:celery worker --loglevel=info -n worker3@h --concurrency=4
```

Ou usando `autoscaling` com supervisores como `supervisord`, `systemd` ou Docker Compose/Kubernetes.

---

## âœ… Testando a API

FaÃ§a um `POST` para a rota:

```
POST http://localhost:8000/processar/
Content-Type: application/json

{
  "dado": "valor importante"
}
```

A resposta serÃ¡ imediata:
```json
{"message": "Tarefa recebida e estÃ¡ sendo processada."}
```

E o processamento ocorrerÃ¡ no Celery.

---

## ğŸ›¡ï¸ SeguranÃ§a

- Altere o `usuario:senha` no `celery_app.py` e nas variÃ¡veis de ambiente do RabbitMQ.
- NÃ£o exponha o Flower sem autenticaÃ§Ã£o ou via HTTPS.
- Use variÃ¡veis de ambiente (ex: com `python-dotenv`) para senhas e configs sensÃ­veis.

---

## ğŸ§¹ Futuras melhorias

- Adicionar `.env` para configs
- Deploy com Docker Compose
- Tasks encadeadas, retries, timeouts
- IntegraÃ§Ã£o com Redis como resultado e cache

